{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Q11pHVWci6H7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/train.csv', parse_dates=['date'])\n",
        "print(df.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25pUEyJujbKs",
        "outputId": "e4608c0a-aaeb-448d-9683-84b3fcdc65ae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    id       date    city       lat      long       pop    shop        brand  \\\n",
            "0  0.0 2012-01-31  Athens  37.97945  23.71622  672130.0  shop_1  kinder-cola   \n",
            "1  1.0 2012-01-31  Athens  37.97945  23.71622  672130.0  shop_1  kinder-cola   \n",
            "2  2.0 2012-01-31  Athens  37.97945  23.71622  672130.0  shop_1  kinder-cola   \n",
            "3  3.0 2012-01-31  Athens  37.97945  23.71622  672130.0  shop_1   adult-cola   \n",
            "4  4.0 2012-01-31  Athens  37.97945  23.71622  672130.0  shop_1   adult-cola   \n",
            "\n",
            "  container capacity  price  quantity  \n",
            "0     glass    500ml   0.96   13280.0  \n",
            "1   plastic    1.5lt   2.86    6727.0  \n",
            "2       can    330ml   0.87    9848.0  \n",
            "3     glass    500ml   1.00   20050.0  \n",
            "4       can    330ml   0.39   25696.0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-7f56736f24dd>:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df = pd.read_csv('/content/train.csv', parse_dates=['date'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
        "df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce')\n",
        "df = df.dropna(subset=['price', 'quantity'])\n"
      ],
      "metadata": {
        "id": "D81vZg9BjzPe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groups = df.groupby('city')"
      ],
      "metadata": {
        "id": "3hFTKsibjzS7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {}\n",
        "results = {}"
      ],
      "metadata": {
        "id": "4YHZkDJzjzXV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, group in groups:\n",
        "    print(f'Processing {name}')\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPB-mF2Ejzbm",
        "outputId": "bf9fc7e4-b9a2-4bea-906b-43741e40b98d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Athens\n",
            "Processing Irakleion\n",
            "Processing Larisa\n",
            "Processing Patra\n",
            "Processing Thessaloniki\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "group = group.sort_values(by='date')"
      ],
      "metadata": {
        "id": "0YwqUkTUkDNa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group['sales'] = group['price'] * group['quantity']\n",
        "daily_sales = group.resample('D', on='date').sum()['sales']"
      ],
      "metadata": {
        "id": "BZSI5wDTkWjm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    model = ExponentialSmoothing(daily_sales, trend='add', seasonal='add', seasonal_periods=7).fit()\n",
        "    models[name] = model\n",
        "    forecast = model.forecast(steps=10)\n",
        "    results[name] = forecast\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "o6RTVeQ7kWnr",
        "outputId": "712d44a2-2c74-40c8-d2a8-c28ec3662f56"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-47-82448b9e84c5>, line 7)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-47-82448b9e84c5>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'city1' in models:\n",
        "    print(models['city1'].summary())\n",
        "    print(results['city1'])\n",
        "else:\n",
        "    print(\"City 'city1' not found in the dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_D2K1LCkWsR",
        "outputId": "1a08f0a7-fe68-48bf-9c05-602d4f016ab1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "City 'city1' not found in the dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_single_city(city_name):\n",
        "    if city_name in df['city'].unique():\n",
        "        city_data = df[df['city'] == city_name]\n",
        "        city_data = city_data.sort_values(by='date')\n",
        "        city_data['sales'] = city_data['price'] * city_data['quantity']\n",
        "        daily_sales = city_data.resample('D', on='date').sum()['sales']\n",
        "        model = ExponentialSmoothing(daily_sales, trend='add', seasonal='add', seasonal_periods=7).fit()\n",
        "        forecast = model.forecast(steps=10)\n",
        "        assert len(forecast) == 10\n",
        "    else:\n",
        "        print(f\"City '{city_name}' not found in the dataset\")\n",
        "\n",
        "test_single_city('city1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk7vhabbkWwO",
        "outputId": "ccebf338-5eb3-4b4e-e839-286dc89ea0b7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "City 'city1' not found in the dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Define a function for time series cross-validation\n",
        "def time_series_cv(data, n_splits):\n",
        "    # Create a TimeSeriesSplit object\n",
        "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "    # Initialize a list to store the errors\n",
        "    errors = []\n",
        "\n",
        "    # Loop over the splits\n",
        "    for train_index, test_index in tscv.split(data):\n",
        "        # Split the data into training and test sets\n",
        "        train, test = data.iloc[train_index], data.iloc[test_index]\n",
        "\n",
        "        # Fit the Exponential Smoothing model\n",
        "        model = ExponentialSmoothing(train, trend='add', seasonal='add', seasonal_periods=7).fit()\n",
        "\n",
        "        # Forecast the test set\n",
        "        forecast = model.forecast(len(test))\n",
        "\n",
        "        # Calculate the mean squared error\n",
        "        error = mean_squared_error(test, forecast)\n",
        "\n",
        "        # Append the error to the list\n",
        "        errors.append(error)\n",
        "\n",
        "    # Return the average error\n",
        "    return np.mean(errors)\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'data' is a pandas Series with your time series data\n",
        "# data = pd.Series([...])\n",
        "# print(time_series_cv(data, 5))\n",
        "\n"
      ],
      "metadata": {
        "id": "i3adILcKkWz9"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'city1' in df['city'].unique():\n",
        "    city_data = df[df['city'] == 'city1']\n",
        "    city_data = city_data.sort_values(by='date')\n",
        "    city_data['sales'] = city_data['price'] * city_data['quantity']\n",
        "    daily_sales = city_data.resample('D', on='date').sum()['sales'].values\n",
        "    cv_error = time_series_cv(daily_sales, n_splits=5)\n",
        "    print(f'Cross-Validation Error: {cv_error}')\n",
        "else:\n",
        "    print(\"City 'city1' not found in the dataset\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN_fZ8m3mNmf",
        "outputId": "eab44b8d-2688-47f3-dd3c-8e591b587183"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "City 'city1' not found in the dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance = {}\n",
        "for name, group in groups:\n",
        "    group = group.sort_values(by='date')\n",
        "    group['sales'] = group['price'] * group['quantity']\n",
        "    daily_sales = group.resample('D', on='date').sum()['sales']\n",
        "    model = models.get(name)\n",
        "    if model:\n",
        "        forecast = results[name]\n",
        "        true_values = daily_sales[-len(forecast):]  # Assuming the last 'len(forecast)' entries are the test set\n",
        "        mse = mean_squared_error(true_values, forecast)\n",
        "        performance[name] = mse\n",
        "        print(performance)"
      ],
      "metadata": {
        "id": "jbfAo2UEmZYU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_forecast(city_name):\n",
        "    if city_name in groups.groups:\n",
        "        group = groups.get_group(city_name).sort_values(by='date')\n",
        "        group['sales'] = group['price'] * group['quantity']\n",
        "        daily_sales = group.resample('D', on='date').sum()['sales']\n",
        "        model = models.get(city_name)\n",
        "        if model:\n",
        "            forecast = results[city_name]\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.plot(daily_sales, label='True Values')\n",
        "            plt.plot(forecast, label='Forecast', linestyle='--')\n",
        "            plt.title(f'Forecast vs True Values for {city_name}')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(f\"No model found for {city_name}\")\n",
        "    else:\n",
        "        print(f\"City '{city_name}' not found in the dataset\")"
      ],
      "metadata": {
        "id": "fbttTYagmiem"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = pd.DataFrame.from_dict(performance, orient='index', columns=['MSE'])\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4N3-YGnmp9K",
        "outputId": "f4ed6908-616a-4bc2-ce2d-05ba2c2a184e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [MSE]\n",
            "Index: []\n"
          ]
        }
      ]
    }
  ]
}